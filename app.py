"""NeuroWriter - Streamlit Web Application (Interactive Self-Evolving Pipeline)"""
import streamlit as st
import logging
from typing import Optional
from core.pipeline_orchestrator import PipelineOrchestrator, MAX_EVOLUTION_ITERATIONS
from core.fact_checker import FactChecker
from core.llm_client import get_llm_client
import config

logger = logging.getLogger(__name__)
logging.basicConfig(level=config.LOG_LEVEL)

# Configure page
st.set_page_config(
    page_title="NeuroWriter",
    page_icon="ğŸ§ ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
.main {
    padding: 2rem;
}
.stChatMessage {
    background-color: #f0f2f6;
    padding: 1rem;
    border-radius: 0.5rem;
    margin: 0.5rem 0;
}
</style>
""", unsafe_allow_html=True)


# ------------------------------------------------------------------
# Session state initialization
# ------------------------------------------------------------------

def initialize_session():
    """Initialize session state variables"""
    defaults = {
        "history": [],
        "current_topic": None,
        "generation_result": None,
        "fact_check_result": None,
        "chat_messages": [],
        "current_intro": None,
        "current_references": None,
        "collected_papers": None,
        "parsed_topic": None,
        # Pipeline state machine
        "pipeline_state": "IDLE",
        "pipeline_iteration": 0,
        "topic_analysis": None,
        "search_queries": [],
        "paper_pool": [],
        "landscape": {},
        "reference_pool": [],
        "writing_strategy": {},
        "introduction_text": "",
        "evaluation_result": {},
        "iteration_history": [],
        # Orchestrator recreation
        "api_key_stored": "",
        "model_stored": "",
    }
    for key, default in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = default


def reset_pipeline():
    """Reset pipeline state to IDLE"""
    keys = [
        "pipeline_state", "pipeline_iteration", "topic_analysis",
        "search_queries", "paper_pool", "landscape", "reference_pool",
        "writing_strategy", "introduction_text", "evaluation_result",
        "iteration_history", "generation_result", "current_topic",
        "fact_check_result",
    ]
    defaults = {
        "pipeline_state": "IDLE",
        "pipeline_iteration": 0,
        "topic_analysis": None,
        "search_queries": [],
        "paper_pool": [],
        "landscape": {},
        "reference_pool": [],
        "writing_strategy": {},
        "introduction_text": "",
        "evaluation_result": {},
        "iteration_history": [],
        "generation_result": None,
        "current_topic": None,
        "fact_check_result": None,
    }
    for k in keys:
        st.session_state[k] = defaults.get(k)


def get_orchestrator() -> Optional[PipelineOrchestrator]:
    """Create PipelineOrchestrator from stored credentials"""
    api_key = st.session_state.get("api_key_stored", "")
    model = st.session_state.get("model_stored", "gpt-4o")
    if not api_key or not api_key.startswith("sk-"):
        return None
    try:
        return PipelineOrchestrator(api_key=api_key, model=model)
    except Exception as e:
        logger.error(f"Failed to create orchestrator: {e}")
        return None


# ------------------------------------------------------------------
# Header & sidebar
# ------------------------------------------------------------------

def display_header():
    """Display application header"""
    st.markdown("# ğŸ§  NeuroWriter")
    st.markdown(
        "**EEG/Deep Learning ì˜í•™ë…¼ë¬¸ Introduction Generator**  \n"
        "ë‡ŒíŒŒì™€ ë”¥ëŸ¬ë‹ ê¸°ë°˜ ì‹ ê²½ê³¼/ì •ì‹ ê³¼ ì—°êµ¬ ì£¼ì œë¥¼ ì…ë ¥í•˜ë©´, "
        "PubMed ë…¼ë¬¸ì„ ì¸ìš©í•˜ë©° ì˜ì–´ Introductionì„ ìë™ ìƒì„±í•©ë‹ˆë‹¤."
    )


def setup_sidebar():
    """Setup sidebar configuration"""
    with st.sidebar:
        st.markdown("## âš™ï¸ ì„¤ì •")

        # API Key input
        api_key = st.text_input(
            "OpenAI API Key",
            type="password",
            help="https://platform.openai.com/api-keysì—ì„œ ë°œê¸‰ë°›ìœ¼ì„¸ìš”"
        )

        # Model selector
        model = st.selectbox(
            "LLM Model",
            ["gpt-4o", "gpt-4-turbo", "gpt-3.5-turbo"],
            index=0
        )

        # Store for orchestrator recreation
        st.session_state.api_key_stored = api_key
        st.session_state.model_stored = model

        # Reference style
        st.markdown("### ì°¸ê³ ë¬¸í—Œ ìŠ¤íƒ€ì¼")
        reference_style = st.selectbox(
            "Citation Style",
            ["APA", "Vancouver", "AMA"],
            index=0,
            help="APA: Author (Year). Title. Journal.\nVancouver: Number. Author. Title. Journal. Year.\nAMA: Author. Title. Journal. Year;Vol(Issue):Pages."
        )

        # Cache management
        st.markdown("### ìºì‹œ ê´€ë¦¬")
        from utils.cache import PubmedCache
        cache = PubmedCache()
        stats = cache.get_stats()
        st.write(f"ë…¼ë¬¸: {stats['article_count']}ê±´ | ê²€ìƒ‰: {stats['search_count']}ê±´")
        if st.button("ìºì‹œ ì´ˆê¸°í™”", key="clear_cache_btn"):
            cache.clear_cache()
            st.success("ìºì‹œê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤")
            st.rerun()

        # Pipeline state indicator
        state = st.session_state.pipeline_state
        if state != "IDLE":
            st.markdown("### íŒŒì´í”„ë¼ì¸ ìƒíƒœ")
            state_labels = {
                "IDLE": "ëŒ€ê¸°",
                "PARSING": "ì£¼ì œ ë¶„ì„ ì¤‘",
                "CONFIRM_QUERIES": "ì¿¼ë¦¬ í™•ì¸ ëŒ€ê¸°",
                "RESEARCHING": "ë¦¬ì„œì¹˜ ìˆ˜í–‰ ì¤‘",
                "CONFIRM_STRATEGY": "ì „ëµ í™•ì¸ ëŒ€ê¸°",
                "GENERATING": "Introduction ì‘ì„± ì¤‘",
                "EVALUATING": "í’ˆì§ˆ í‰ê°€ ì¤‘",
                "SELF_EVOLVING": "ìë™ ê°œì„  ì¤‘",
                "COMPLETE": "ì™„ë£Œ",
            }
            st.info(f"í˜„ì¬ ìƒíƒœ: **{state_labels.get(state, state)}**")
            iteration = st.session_state.pipeline_iteration
            if iteration > 0:
                st.write(f"Self-evolution ë°˜ë³µ: {iteration}/{MAX_EVOLUTION_ITERATIONS}")

        # History
        st.markdown("### ğŸ“‹ ìƒì„± ì´ë ¥")
        if st.session_state.history:
            for i, item in enumerate(st.session_state.history):
                if st.button(f"{i+1}. {item['topic'][:40]}...", key=f"history_{i}"):
                    st.session_state.current_topic = item["topic"]
                    st.session_state.generation_result = item["result"]
                    st.session_state.pipeline_state = "COMPLETE"
        else:
            st.info("ìƒì„± ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤")

        st.markdown("---")
        st.markdown("### ğŸ“– ì •ë³´")
        st.markdown(
            "[GitHub](https://github.com/anthropics/claude-code) | "
            "[ë¬¸ì„œ](https://github.com/anthropics/claude-code/blob/main/README.md)"
        )

        return api_key, model, reference_style


# ------------------------------------------------------------------
# State renderers
# ------------------------------------------------------------------

def render_idle_state():
    """IDLE: Topic input and start"""
    st.markdown("## ì—°êµ¬ ì£¼ì œ ì…ë ¥")

    topic = st.text_area(
        "ì—°êµ¬ ì£¼ì œë¥¼ í•œ ì¤„ë¡œ ì…ë ¥í•˜ì„¸ìš”",
        placeholder="ì˜ˆ: ë‡ŒíŒŒ ë”¥ëŸ¬ë‹ ë¶„ì„ ê¸°ë°˜ ì£¼ìš”ìš°ìš¸ì¥ì• ì˜ í•­ìš°ìš¸ì œ ì¹˜ë£Œ ë°˜ì‘ì„± ì˜ˆì¸¡ ì—°êµ¬",
        height=100,
        help="ì§ˆí™˜ëª…, ë°ì´í„° ìœ í˜•, ë¶„ì„ ë°©ë²•, ì˜ˆì¸¡ ëŒ€ìƒ ë“±ì„ í¬í•¨í•˜ë©´ ë” ì¢‹ìŠµë‹ˆë‹¤"
    )

    col1, col2 = st.columns([1, 3])
    with col1:
        start_btn = st.button("ğŸš€ ì‹œì‘", key="start_btn")

    if start_btn:
        if not topic.strip():
            st.error("ì—°êµ¬ ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”")
            return
        api_key = st.session_state.api_key_stored
        if not api_key or not api_key.startswith("sk-"):
            st.error("ìœ íš¨í•œ OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
            return

        st.session_state.current_topic = topic
        st.session_state.pipeline_state = "PARSING"
        st.rerun()


def render_parsing_state():
    """PARSING: Parse topic (auto-advance)"""
    st.markdown("## ì£¼ì œ ë¶„ì„ ì¤‘...")

    orch = get_orchestrator()
    if not orch:
        st.error("API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”")
        st.session_state.pipeline_state = "IDLE"
        return

    with st.spinner("ì£¼ì œë¥¼ ì‹¬ì¸µ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
        try:
            topic_analysis = orch.parse_topic(st.session_state.current_topic)
            st.session_state.topic_analysis = topic_analysis
            st.session_state.search_queries = topic_analysis.get("search_queries", [])
            st.session_state.pipeline_state = "CONFIRM_QUERIES"
            st.rerun()
        except Exception as e:
            st.error(f"ì£¼ì œ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            logger.error(f"Topic parsing error: {e}", exc_info=True)
            st.session_state.pipeline_state = "IDLE"


def render_confirm_queries_state():
    """CONFIRM_QUERIES: Checkpoint 1 - user reviews/edits queries"""
    st.markdown("## ê²€ìƒ‰ ì¿¼ë¦¬ í™•ì¸ (ì²´í¬í¬ì¸íŠ¸ 1)")

    topic_analysis = st.session_state.topic_analysis
    if not topic_analysis:
        st.session_state.pipeline_state = "IDLE"
        st.rerun()
        return

    # Display parsed topic info
    st.markdown("### íŒŒì‹±ëœ ì£¼ì œ ì •ë³´")
    col1, col2 = st.columns(2)
    with col1:
        st.write(f"**ì§ˆí™˜:** {topic_analysis.get('disease', 'N/A')}")
        st.write(f"**ë°ì´í„° ìœ í˜•:** {topic_analysis.get('data_type', 'N/A')}")
        st.write(f"**í•µì‹¬ ì´ˆì :** {topic_analysis.get('key_intervention_or_focus', 'N/A')}")
    with col2:
        st.write(f"**ë°©ë²•ë¡ :** {topic_analysis.get('methodology', 'N/A')}")
        st.write(f"**ì˜ˆì¸¡ ëŒ€ìƒ:** {topic_analysis.get('outcome', 'N/A')}")

    # Concept hierarchy
    concepts = topic_analysis.get("concept_hierarchy", [])
    if concepts:
        with st.expander("ê°œë… ê³„ì¸µêµ¬ì¡°", expanded=False):
            for concept in concepts[:8]:
                st.write(f"  - {concept}")

    # Editable search queries
    st.markdown("### ê²€ìƒ‰ ì¿¼ë¦¬ (í¸ì§‘ ê°€ëŠ¥)")
    st.caption("í•œ ì¤„ì— í•˜ë‚˜ì˜ ì¿¼ë¦¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”. ì¿¼ë¦¬ë¥¼ ì¶”ê°€/ì‚­ì œ/ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    queries_text = st.text_area(
        "ê²€ìƒ‰ ì¿¼ë¦¬",
        value="\n".join(st.session_state.search_queries),
        height=300,
        key="edit_queries"
    )

    # Additional feedback
    additional_feedback = st.text_area(
        "ì¶”ê°€ í”¼ë“œë°± (ì„ íƒì‚¬í•­)",
        placeholder="íŠ¹ë³„íˆ í¬í•¨í•˜ê³  ì‹¶ì€ ê²€ìƒ‰ ì „ëµì´ë‚˜ ê°•ì¡°ì ì´ ìˆìœ¼ë©´ ì‘ì„±í•˜ì„¸ìš”",
        height=80,
        key="query_feedback"
    )

    col1, col2 = st.columns(2)
    with col1:
        confirm_btn = st.button("í™•ì¸ & ë¦¬ì„œì¹˜ ì‹œì‘", key="confirm_queries_btn")
    with col2:
        back_btn = st.button("ì£¼ì œ ìˆ˜ì •ìœ¼ë¡œ ëŒì•„ê°€ê¸°", key="back_to_idle_btn")

    if confirm_btn:
        edited_queries = [q.strip() for q in queries_text.split("\n") if q.strip()]
        if not edited_queries:
            st.error("ìµœì†Œ í•˜ë‚˜ì˜ ê²€ìƒ‰ ì¿¼ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤")
            return

        orch = get_orchestrator()
        if not orch:
            st.error("API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”")
            return

        st.session_state.topic_analysis = orch.update_queries(
            st.session_state.topic_analysis, edited_queries
        )
        st.session_state.search_queries = edited_queries
        st.session_state.pipeline_state = "RESEARCHING"
        st.rerun()

    if back_btn:
        reset_pipeline()
        st.rerun()


def render_researching_state():
    """RESEARCHING: Run research pipeline with per-query progress"""
    st.markdown("## ë¦¬ì„œì¹˜ ìˆ˜í–‰ ì¤‘...")

    orch = get_orchestrator()
    if not orch:
        st.error("API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”")
        st.session_state.pipeline_state = "IDLE"
        return

    status_container = st.status("PubMed ë¦¬ì„œì¹˜ ì§„í–‰ ì¤‘...", expanded=True)

    try:
        with status_container:
            from utils.pubmed_utils import has_valid_abstract

            topic_analysis = st.session_state.topic_analysis
            search_queries = topic_analysis.get("search_queries", [])
            st.write(f"**{len(search_queries)}ê°œ ì¿¼ë¦¬ë¡œ ë…¼ë¬¸ ìˆ˜ì§‘ ì‹œì‘...**")

            # --- Paper collection with per-query feedback ---
            researcher = orch.deep_researcher
            all_papers = {}

            for i, query in enumerate(search_queries, 1):
                try:
                    papers = researcher.pubmed_client.search_and_fetch(
                        query, f"query_{i}", max_results=30
                    )
                    added = 0
                    retracted = 0
                    for paper in papers:
                        pmid = paper.get("pmid")
                        if pmid and pmid not in all_papers and has_valid_abstract(paper):
                            if paper.get("is_retracted", False):
                                retracted += 1
                                continue
                            all_papers[pmid] = paper
                            added += 1
                    retracted_note = f" (retracted {retracted}í¸ ì œì™¸)" if retracted else ""
                    st.write(f"  Query {i}/{len(search_queries)}: +{added}í¸{retracted_note} (ëˆ„ì  {len(all_papers)}í¸) â€” `{query[:55]}`")
                except Exception as e:
                    st.write(f"  Query {i}/{len(search_queries)}: ì‹¤íŒ¨ â€” {str(e)[:50]}")

            # High-impact journal search
            disease = topic_analysis.get("disease", "")
            if disease:
                try:
                    hi_papers = researcher.pubmed_client.search_and_fetch(
                        f"({disease}) AND (Nature[Journal] OR NEJM[Journal] OR Lancet[Journal] OR JAMA[Journal])",
                        "high_impact", max_results=40
                    )
                    added = 0
                    for paper in hi_papers:
                        pmid = paper.get("pmid")
                        if pmid and pmid not in all_papers and has_valid_abstract(paper):
                            if paper.get("is_retracted", False):
                                continue
                            all_papers[pmid] = paper
                            added += 1
                    st.write(f"  High-impact journals: +{added}í¸ (ëˆ„ì  {len(all_papers)}í¸)")
                except Exception as e:
                    st.write(f"  High-impact journals: ì‹¤íŒ¨ â€” {str(e)[:50]}")

            paper_pool = list(all_papers.values())
            st.session_state.paper_pool = paper_pool
            st.write(f"**ì´ {len(paper_pool)}ê°œ ë…¼ë¬¸ ìˆ˜ì§‘ ì™„ë£Œ**")

        # --- 0 papers guard ---
        if not paper_pool:
            st.error(
                "PubMedì—ì„œ ë…¼ë¬¸ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê°€ëŠ¥í•œ ì›ì¸:\n"
                "- ê²€ìƒ‰ ì¿¼ë¦¬ê°€ ë„ˆë¬´ êµ¬ì²´ì ì´ê±°ë‚˜ PubMed ë¬¸ë²•ì— ë§ì§€ ì•ŠìŒ\n"
                "- PubMed API ì¼ì‹œ ì¥ì•  ë˜ëŠ” ë„¤íŠ¸ì›Œí¬ ë¬¸ì œ\n\n"
                "ì¿¼ë¦¬ë¥¼ ìˆ˜ì •í•œ ë’¤ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
            )
            st.session_state.pipeline_state = "CONFIRM_QUERIES"
            return

        # --- Landscape analysis ---
        with st.status("ë¬¸í—Œ ë¶„ì„ ë° ì „ëµ ìˆ˜ë¦½ ì¤‘...", expanded=True) as status2:
            st.write("**ë¬¸í—Œ ê²½ê´€ ë¶„ì„ ì¤‘...**")
            landscape = orch.intro_generator.step_analyze_landscape(
                paper_pool, st.session_state.current_topic
            )
            st.session_state.landscape = landscape
            st.write(f"  í•µì‹¬ ë°œê²¬ì‚¬í•­ {len(landscape.get('key_findings', []))}ê°œ, "
                      f"ë¯¸ì¶©ì¡± ë¶„ì•¼ {len(landscape.get('knowledge_gaps', []))}ê°œ ì‹ë³„")

            # --- Reference pool selection ---
            st.write("**ìµœì  ë…¼ë¬¸ í’€ ì„ ë³„ ì¤‘...**")
            reference_pool = orch.intro_generator.step_select_references(paper_pool, landscape)
            st.session_state.reference_pool = reference_pool
            st.write(f"  {len(reference_pool)}í¸ ì„ ë³„ ì™„ë£Œ")

            # --- Writing strategy ---
            st.write("**Writing strategy ìƒì„± ì¤‘...**")
            strategy = orch.generate_writing_strategy(
                st.session_state.topic_analysis, reference_pool, landscape
            )
            st.session_state.writing_strategy = strategy
            st.write("**ë¦¬ì„œì¹˜ ì™„ë£Œ!**")

        st.session_state.pipeline_state = "CONFIRM_STRATEGY"
        st.rerun()

    except Exception as e:
        st.error(f"ë¦¬ì„œì¹˜ ì‹¤íŒ¨: {str(e)}")
        logger.error(f"Research error: {e}", exc_info=True)
        st.session_state.pipeline_state = "CONFIRM_QUERIES"


def render_confirm_strategy_state():
    """CONFIRM_STRATEGY: Checkpoint 2 - user reviews strategy"""
    st.markdown("## Writing Strategy í™•ì¸ (ì²´í¬í¬ì¸íŠ¸ 2)")

    # Research summary
    st.markdown("### ë¦¬ì„œì¹˜ ìš”ì•½")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ìˆ˜ì§‘ëœ ë…¼ë¬¸", len(st.session_state.paper_pool))
    with col2:
        st.metric("ì„ ë³„ëœ ë…¼ë¬¸", len(st.session_state.reference_pool))
    with col3:
        landscape = st.session_state.landscape
        findings_count = len(landscape.get("key_findings", []))
        st.metric("í•µì‹¬ ë°œê²¬ì‚¬í•­", findings_count)

    # Writing strategy display
    strategy = st.session_state.writing_strategy
    paragraphs = strategy.get("paragraphs", [])
    ref_pool = st.session_state.reference_pool

    if paragraphs:
        st.markdown("### Paragraphë³„ ê³„íš")
        for para in paragraphs:
            num = para.get("paragraph_number", "?")
            topic = para.get("topic", "")
            key_points = para.get("key_points", [])
            refs = para.get("supporting_papers", [])
            transition = para.get("transition_to_next", "")

            with st.expander(f"Paragraph {num}: {topic}", expanded=True):
                st.markdown("**Key Points:**")
                for pt in key_points:
                    st.write(f"  - {pt}")

                # Show reference details
                if refs and ref_pool:
                    st.markdown("**Supporting References:**")
                    for ref_num in refs:
                        idx = ref_num - 1  # 1-indexed to 0-indexed
                        if 0 <= idx < len(ref_pool):
                            paper = ref_pool[idx]
                            authors = paper.get("authors", [])
                            first_author = authors[0] if authors else "Unknown"
                            et_al = " et al." if len(authors) > 1 else ""
                            title = paper.get("title", "")[:80]
                            journal = paper.get("journal_iso", paper.get("journal", ""))
                            year = paper.get("pub_year", "")
                            st.write(f"  [{ref_num}] {first_author}{et_al} â€” {title}... *{journal}* ({year})")
                        else:
                            st.write(f"  [{ref_num}] (ë²”ìœ„ ë°–)")
                elif refs:
                    st.write(f"**Supporting references:** [{', '.join(str(r) for r in refs)}]")

                if transition:
                    st.write(f"**Transition:** {transition}")

    narrative_arc = strategy.get("narrative_arc", "")
    if narrative_arc:
        st.markdown("### Narrative Arc")
        st.info(narrative_arc)

    # Landscape details
    with st.expander("ë¬¸í—Œ ê²½ê´€ ë¶„ì„ ìƒì„¸", expanded=False):
        _display_landscape(st.session_state.landscape)

    # Feedback
    st.markdown("---")
    feedback = st.text_area(
        "ì „ëµì— ëŒ€í•œ í”¼ë“œë°± (ì„ íƒì‚¬í•­)",
        placeholder="ì˜ˆ: 'ë°©ë²•ë¡  íŒŒíŠ¸ë¥¼ ë” ìì„¸í•˜ê²Œ' ë˜ëŠ” 'íŠ¹ì • ë…¼ë¬¸ì„ ë” ê°•ì¡°í•´ì¤˜'",
        height=80,
        key="strategy_feedback"
    )

    col1, col2, col3 = st.columns(3)
    with col1:
        generate_btn = st.button("Introduction ì‘ì„±", key="generate_intro_btn")
    with col2:
        add_research_btn = st.button("ì¶”ê°€ ë¦¬ì„œì¹˜ í›„ ì‘ì„±", key="add_research_btn")
    with col3:
        back_btn = st.button("ì¿¼ë¦¬ ìˆ˜ì •ìœ¼ë¡œ ëŒì•„ê°€ê¸°", key="back_to_queries_btn")

    if generate_btn:
        st.session_state.pipeline_state = "GENERATING"
        st.rerun()

    if add_research_btn:
        st.markdown("### ì¶”ê°€ ë¦¬ì„œì¹˜")
        input_mode = st.radio(
            "ì…ë ¥ ë°©ì‹",
            ["ìì—°ì–´ í”¼ë“œë°± (AIê°€ ì¿¼ë¦¬ ìƒì„±)", "ì§ì ‘ PubMed ì¿¼ë¦¬ ì…ë ¥"],
            key="extra_research_mode"
        )

        if input_mode == "ìì—°ì–´ í”¼ë“œë°± (AIê°€ ì¿¼ë¦¬ ìƒì„±)":
            nl_feedback = st.text_area(
                "ì–´ë–¤ ë¶€ë¶„ì´ ë¶€ì¡±í•œì§€ ìì—°ì–´ë¡œ ì„¤ëª…í•˜ì„¸ìš”",
                placeholder="ì˜ˆ: treatment-resistant MDD ê´€ë ¨ ë…¼ë¬¸ì´ ë¶€ì¡±í•´ìš” / ë°©ë²•ë¡  íŒŒíŠ¸ì— EEG ì „ì²˜ë¦¬ ê´€ë ¨ ë‚´ìš©ì´ í•„ìš”í•´ìš”",
                height=100,
                key="nl_feedback_input"
            )
            if st.button("AI ì¿¼ë¦¬ ìƒì„± & ë¦¬ì„œì¹˜ ì‹¤í–‰", key="run_nl_research_btn"):
                if not nl_feedback.strip():
                    st.warning("í”¼ë“œë°±ì„ ì…ë ¥í•˜ì„¸ìš”")
                else:
                    orch = get_orchestrator()
                    if not orch:
                        st.error("API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”")
                    else:
                        with st.spinner("í”¼ë“œë°±ì„ ë¶„ì„í•˜ì—¬ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                            result = orch.generate_queries_from_feedback(
                                user_feedback=nl_feedback,
                                writing_strategy=st.session_state.writing_strategy,
                                topic_analysis=st.session_state.topic_analysis,
                                landscape=st.session_state.landscape
                            )
                        interpretation = result.get("interpretation", "")
                        queries = result.get("queries", [])
                        if interpretation:
                            st.info(f"**AI í•´ì„:** {interpretation}")
                        if queries:
                            st.write(f"**ìƒì„±ëœ ì¿¼ë¦¬ ({len(queries)}ê°œ):**")
                            for i, q in enumerate(queries, 1):
                                st.write(f"  {i}. `{q}`")
                            _run_supplementary_research(queries)
                        else:
                            st.warning("ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì§ì ‘ ì…ë ¥ì„ ì‹œë„í•´ ì£¼ì„¸ìš”.")
        else:
            extra_queries = st.text_area(
                "ì¶”ê°€ ì¿¼ë¦¬ ì…ë ¥ (í•œ ì¤„ì— í•˜ë‚˜)",
                placeholder="ì¶”ê°€ë¡œ ê²€ìƒ‰í•˜ê³  ì‹¶ì€ ì¿¼ë¦¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”",
                height=120,
                key="extra_queries_input"
            )
            if st.button("ì¶”ê°€ ë¦¬ì„œì¹˜ ì‹¤í–‰", key="run_extra_research_btn"):
                queries = [q.strip() for q in extra_queries.split("\n") if q.strip()]
                if not queries:
                    st.warning("ì¶”ê°€ ì¿¼ë¦¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
                else:
                    _run_supplementary_research(queries)

    if back_btn:
        st.session_state.pipeline_state = "CONFIRM_QUERIES"
        st.rerun()


def _run_supplementary_research(queries: list):
    """Run supplementary research and update state"""
    orch = get_orchestrator()
    if not orch:
        st.error("API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”")
        return

    with st.spinner("ì¶”ê°€ ë¦¬ì„œì¹˜ ìˆ˜í–‰ ì¤‘..."):
        try:
            expanded_pool, updated_landscape, new_ref_pool = orch.run_supplementary_research(
                additional_queries=queries,
                paper_pool=st.session_state.paper_pool,
                landscape=st.session_state.landscape,
                research_topic=st.session_state.current_topic,
                topic_analysis=st.session_state.topic_analysis,
            )
            old_count = len(st.session_state.paper_pool)
            st.session_state.paper_pool = expanded_pool
            st.session_state.landscape = updated_landscape
            st.session_state.reference_pool = new_ref_pool

            # Re-generate writing strategy
            strategy = orch.generate_writing_strategy(
                st.session_state.topic_analysis, new_ref_pool, updated_landscape
            )
            st.session_state.writing_strategy = strategy

            new_count = len(expanded_pool) - old_count
            st.success(f"ì¶”ê°€ ë¦¬ì„œì¹˜ ì™„ë£Œ! {new_count}í¸ ìƒˆ ë…¼ë¬¸ ë°œê²¬. Reference pool: {len(new_ref_pool)}í¸")
            st.rerun()
        except Exception as e:
            st.error(f"ì¶”ê°€ ë¦¬ì„œì¹˜ ì‹¤íŒ¨: {str(e)}")
            logger.error(f"Supplementary research error: {e}", exc_info=True)


def render_generating_state():
    """GENERATING: Generate introduction (auto-advance)"""
    st.markdown("## Introduction ì‘ì„± ì¤‘...")

    orch = get_orchestrator()
    if not orch:
        st.error("API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”")
        st.session_state.pipeline_state = "IDLE"
        return

    with st.spinner("Introductionì„ ì‘ì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
        try:
            introduction = orch.generate_introduction(
                st.session_state.topic_analysis,
                st.session_state.reference_pool,
                st.session_state.landscape
            )
            st.session_state.introduction_text = introduction
            st.session_state.pipeline_state = "EVALUATING"
            st.rerun()
        except Exception as e:
            st.error(f"Introduction ì‘ì„± ì‹¤íŒ¨: {str(e)}")
            logger.error(f"Generation error: {e}", exc_info=True)
            st.session_state.pipeline_state = "CONFIRM_STRATEGY"


def render_evaluating_state():
    """EVALUATING: Run 8-criterion evaluation (auto-advance)"""
    st.markdown("## í’ˆì§ˆ í‰ê°€ ì¤‘...")

    orch = get_orchestrator()
    if not orch:
        st.error("API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”")
        st.session_state.pipeline_state = "IDLE"
        return

    with st.spinner("8ê°œ ê¸°ì¤€ìœ¼ë¡œ í’ˆì§ˆì„ í‰ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
        try:
            evaluation = orch.evaluate_introduction(
                st.session_state.introduction_text,
                st.session_state.reference_pool,
                st.session_state.topic_analysis,
                st.session_state.landscape
            )
            st.session_state.evaluation_result = evaluation

            # Auto fact-check
            try:
                fact_result = orch.run_fact_check(
                    st.session_state.introduction_text,
                    st.session_state.reference_pool
                )
                st.session_state.fact_check_result = fact_result

                # Adjust factual_accuracy based on fact-check
                fc_accuracy = fact_result.get("overall_accuracy", "HIGH")
                current_fa = evaluation.get("scores", {}).get("factual_accuracy", 10)
                if fc_accuracy == "LOW":
                    evaluation["scores"]["factual_accuracy"] = min(current_fa, 5)
                elif fc_accuracy == "MEDIUM":
                    evaluation["scores"]["factual_accuracy"] = min(current_fa, 6)

                # Recalculate overall score
                scores = evaluation.get("scores", {})
                if scores:
                    evaluation["overall_score"] = round(
                        sum(scores.values()) / len(scores), 1
                    )
            except Exception as fc_err:
                logger.warning(f"Auto fact-check failed (non-blocking): {fc_err}")

            # Record iteration history
            iteration = st.session_state.pipeline_iteration
            st.session_state.iteration_history.append({
                "iteration": iteration,
                "label": "Draft" if iteration == 0 else f"Rev{iteration}",
                "introduction": st.session_state.introduction_text,
                "evaluation": evaluation,
            })

            # Check if self-evolution is needed
            if (
                orch.needs_self_evolution(evaluation)
                and st.session_state.pipeline_iteration < MAX_EVOLUTION_ITERATIONS
            ):
                st.session_state.pipeline_state = "SELF_EVOLVING"
            else:
                st.session_state.pipeline_state = "COMPLETE"

            st.rerun()

        except Exception as e:
            st.error(f"í’ˆì§ˆ í‰ê°€ ì‹¤íŒ¨: {str(e)}")
            logger.error(f"Evaluation error: {e}", exc_info=True)
            # Still go to COMPLETE with what we have
            st.session_state.pipeline_state = "COMPLETE"
            st.rerun()


def render_self_evolving_state():
    """SELF_EVOLVING: Auto-improve introduction"""
    iteration = st.session_state.pipeline_iteration + 1
    st.markdown(f"## ìë™ ê°œì„  ì¤‘ (Iteration {iteration}/{MAX_EVOLUTION_ITERATIONS})")

    orch = get_orchestrator()
    if not orch:
        st.error("API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”")
        st.session_state.pipeline_state = "COMPLETE"
        st.rerun()
        return

    status_container = st.status("Self-evolution ì§„í–‰ ì¤‘...", expanded=True)

    try:
        with status_container:
            # Step 1: Extract unsupported claims
            st.write("ë¯¸ì§€ì§€ í´ë ˆì„ ì¶”ì¶œ ì¤‘...")
            claims = orch.extract_unsupported_claims(
                st.session_state.evaluation_result,
                st.session_state.introduction_text
            )
            st.write(f"  {len(claims)}ê°œ ë¯¸ì§€ì§€ í´ë ˆì„ ë°œê²¬")

            if not claims:
                st.write("ë¯¸ì§€ì§€ í´ë ˆì„ì´ ì—†ìŠµë‹ˆë‹¤. ì™„ë£Œë¡œ ì´ë™í•©ë‹ˆë‹¤.")
                st.session_state.pipeline_state = "COMPLETE"
                st.rerun()
                return

            # Step 2: Generate supplementary queries
            st.write("ë³´ì¶© ì¿¼ë¦¬ ìƒì„± ì¤‘...")
            queries = orch.generate_supplementary_queries(
                claims, st.session_state.topic_analysis
            )
            st.write(f"  {len(queries)}ê°œ ë³´ì¶© ì¿¼ë¦¬ ìƒì„±")

            # Step 3: Search PubMed
            st.write("PubMed ë³´ì¶© ê²€ìƒ‰ ì¤‘...")
            new_papers = orch.run_supplementary_search(
                queries, st.session_state.paper_pool
            )
            st.write(f"  {len(new_papers)}í¸ ìƒˆ ë…¼ë¬¸ ë°œê²¬")

            # Step 4: Expand reference pool
            if new_papers:
                st.write("Reference pool í™•ì¥ ì¤‘...")
                st.session_state.paper_pool = st.session_state.paper_pool + new_papers
                new_ref_pool = orch.expand_reference_pool(
                    st.session_state.reference_pool,
                    new_papers,
                    st.session_state.landscape
                )
                old_size = len(st.session_state.reference_pool)
                st.session_state.reference_pool = new_ref_pool
                st.write(f"  Reference pool: {old_size} -> {len(new_ref_pool)}í¸")

            # Step 5: Regenerate introduction
            st.write("Introduction ì¬ì‘ì„± ì¤‘...")
            introduction = orch.generate_introduction(
                st.session_state.topic_analysis,
                st.session_state.reference_pool,
                st.session_state.landscape
            )
            st.session_state.introduction_text = introduction

        st.session_state.pipeline_iteration = iteration
        st.session_state.pipeline_state = "EVALUATING"
        st.rerun()

    except Exception as e:
        st.error(f"ìë™ ê°œì„  ì‹¤íŒ¨: {str(e)}")
        logger.error(f"Self-evolution error: {e}", exc_info=True)
        st.session_state.pipeline_state = "COMPLETE"
        st.rerun()


def render_complete_state(reference_style: str = "APA"):
    """COMPLETE: Show final results"""
    st.markdown("## ğŸ“ ìµœì¢… ê²°ê³¼")

    # Build final result for display & history
    result = _build_final_result()
    st.session_state.generation_result = result

    # Metrics
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ìˆ˜ì§‘ëœ ë…¼ë¬¸", len(st.session_state.paper_pool))
    with col2:
        st.metric("ì„ ë³„ëœ ë…¼ë¬¸", len(st.session_state.reference_pool))
    with col3:
        iterations = st.session_state.pipeline_iteration
        label = "Draft" if iterations == 0 else f"Draft + {iterations} Rev"
        st.metric("Iterations", label)

    # Iteration history tabs
    history = st.session_state.iteration_history
    if len(history) > 1:
        st.markdown("### ë²„ì „ ë¹„êµ")
        tab_names = [h["label"] for h in history]
        tabs = st.tabs(tab_names)
        for tab, h in zip(tabs, history):
            with tab:
                eval_data = h.get("evaluation", {})
                overall = eval_data.get("overall_score", "?")
                factual = eval_data.get("scores", {}).get("factual_accuracy", "?")
                st.write(f"**ì¢…í•© ì ìˆ˜:** {overall}/10 | **Factual accuracy:** {factual}/10")
                st.markdown(h["introduction"])
    elif history:
        # Single version â€” show it directly
        pass

    # Display final introduction
    st.markdown("---")
    st.markdown("### Introduction")
    st.markdown(st.session_state.introduction_text)

    # References
    st.markdown("### ğŸ“– References")
    ref_pool = st.session_state.reference_pool
    if ref_pool:
        formatted_refs = _format_references_by_style(ref_pool, reference_style)
        for ref in formatted_refs:
            st.markdown(ref)

    # Evaluation results
    evaluation = st.session_state.evaluation_result
    if evaluation:
        display_self_evaluation_results(evaluation)

    # Auto fact-check results
    fact_result = st.session_state.get("fact_check_result")
    if fact_result:
        st.markdown("---")
        st.markdown("## ìë™ íŒ©íŠ¸ì²´í¬ ê²°ê³¼")
        fc_accuracy = fact_result.get("overall_accuracy", "UNKNOWN")
        fc_issues = fact_result.get("issues", [])
        col1, col2 = st.columns(2)
        with col1:
            st.metric("ì •í™•ë„", fc_accuracy)
        with col2:
            st.metric("ë°œê²¬ëœ ì´ìŠˆ", len(fc_issues))

        # Claim-citation mapping details
        claim_mapping = fact_result.get("claim_mapping", {})
        claim_mappings = claim_mapping.get("claim_mappings", [])
        if claim_mappings:
            with st.expander(f"Claim-Citation ë§¤í•‘ ê²€ì¦ ({len(claim_mappings)}ê°œ claim)", expanded=False):
                for cm in claim_mappings:
                    supported = cm.get("is_supported", True)
                    icon = "+" if supported else "X"
                    claim_text = cm.get("claim", "")[:120]
                    st.write(f"{icon} **{claim_text}**{'...' if len(cm.get('claim', '')) > 120 else ''}")
                    if not supported and cm.get("issue"):
                        st.write(f"   Issue: {cm['issue']}")

        numerical_mismatches = claim_mapping.get("numerical_mismatches", [])
        if numerical_mismatches:
            with st.expander(f"ìˆ˜ì¹˜ ë¶ˆì¼ì¹˜ ({len(numerical_mismatches)}ê±´)", expanded=False):
                for nm in numerical_mismatches:
                    severity = nm.get("severity", "minor").upper()
                    st.write(f"[{severity}] Claimed: {nm.get('claimed_value', '?')} vs Actual: {nm.get('actual_value', '?')}")
                    st.write(f"  {nm.get('claim', '')[:100]}")

        if fc_issues:
            with st.expander(f"íŒ©íŠ¸ì²´í¬ ì´ìŠˆ ìƒì„¸ ({len(fc_issues)}ê±´)", expanded=False):
                for issue in fc_issues:
                    st.write(f"- **{issue.get('type', '')}**: {issue.get('description', '')}")

    # Landscape details
    with st.expander("ğŸŒ ë¬¸í—Œ ê²½ê´€ ë¶„ì„", expanded=False):
        _display_landscape(st.session_state.landscape)

    # Topic details
    topic_analysis = st.session_state.topic_analysis
    if topic_analysis:
        with st.expander("ğŸ“‹ íŒŒì‹±ëœ ì£¼ì œ ì •ë³´", expanded=False):
            col1, col2 = st.columns(2)
            with col1:
                st.write(f"**ì§ˆí™˜:** {topic_analysis.get('disease', 'N/A')}")
                st.write(f"**ë°ì´í„° ìœ í˜•:** {topic_analysis.get('data_type', 'N/A')}")
            with col2:
                st.write(f"**ë°©ë²•ë¡ :** {topic_analysis.get('methodology', 'N/A')}")
                st.write(f"**ì˜ˆì¸¡ ëŒ€ìƒ:** {topic_analysis.get('outcome', 'N/A')}")

    # Action buttons
    st.markdown("---")
    col1, col2, col3 = st.columns(3)

    with col1:
        if st.button("ğŸ“‹ Introduction ë³µì‚¬"):
            st.write("ë³µì‚¬ë˜ì—ˆìŠµë‹ˆë‹¤ (ë¸Œë¼ìš°ì € ë³µì‚¬ ê¸°ëŠ¥ ì‚¬ìš©)")

    with col2:
        fc_label = "âœ… íŒ©íŠ¸ì²´í¬ ì¬ì‹¤í–‰" if fact_result else "âœ… íŒ©íŠ¸ì²´í¬ ì‹¤í–‰"
        if st.button(fc_label, key="factcheck_btn"):
            run_fact_check(result)

    with col3:
        if st.button("ğŸ”„ ìƒˆ ì£¼ì œ ì‹œì‘", key="new_topic_btn"):
            # Save to history before reset
            if st.session_state.current_topic and result:
                st.session_state.history.append({
                    "topic": st.session_state.current_topic,
                    "result": result
                })
            reset_pipeline()
            st.rerun()

    # Manual revision section
    st.markdown("---")
    st.markdown("### ìˆ˜ì •í•˜ê³  ì‹¶ì€ ë¶€ë¶„ì´ ìˆìœ¼ì‹ ê°€ìš”?")

    revision_request = st.text_area(
        "ìˆ˜ì • ìš”ì²­ ì…ë ¥",
        placeholder="ì˜ˆ: 'ë‘ ë²ˆì§¸ ë¬¸ë‹¨ì„ ë” ë³´ê°•í•´ì¤˜' ë˜ëŠ” 'ì „ì²´ì ìœ¼ë¡œ í†¤ì„ ë” formalí•˜ê²Œ ë°”ê¿”ì¤„ë˜'",
        height=80,
        key="revision_request"
    )

    if st.button("ìˆ˜ì • ëª…ë ¹ ì‹¤í–‰", key="run_revision_btn"):
        if not revision_request:
            st.warning("ìˆ˜ì • ìš”ì²­ì„ ì…ë ¥í•˜ì„¸ìš”")
        else:
            run_revision(
                st.session_state.introduction_text,
                revision_request,
                st.session_state.api_key_stored,
                st.session_state.model_stored,
                st.session_state.reference_pool
            )


def _build_final_result() -> dict:
    """Build a result dictionary from current pipeline state"""
    from utils.pubmed_utils import format_citation_vancouver
    references = []
    for i, article in enumerate(st.session_state.reference_pool, 1):
        citation = format_citation_vancouver(article, i)
        references.append(citation)

    return {
        "introduction": st.session_state.introduction_text,
        "references": references,
        "articles_used": st.session_state.reference_pool,
        "parsing_result": st.session_state.topic_analysis or {},
        "landscape": st.session_state.landscape,
        "paper_pool_size": len(st.session_state.paper_pool),
        "reference_pool_size": len(st.session_state.reference_pool),
        "evaluation": st.session_state.evaluation_result,
    }


# ------------------------------------------------------------------
# Shared display helpers
# ------------------------------------------------------------------

def _display_landscape(landscape: dict):
    """Display landscape analysis details"""
    field_overview = landscape.get("field_overview", "")
    if field_overview:
        st.markdown("**ë¶„ì•¼ ê°œìš”:**")
        st.markdown(field_overview)

    key_findings = landscape.get("key_findings", [])
    if key_findings:
        st.markdown(f"\n**í•µì‹¬ ë°œê²¬ì‚¬í•­ ({len(key_findings)}ê°œ):**")
        for i, finding in enumerate(key_findings, 1):
            st.markdown(f"{i}. {finding}")

    knowledge_gaps = landscape.get("knowledge_gaps", [])
    if knowledge_gaps:
        st.markdown(f"\n**ë¯¸ì¶©ì¡± ì—°êµ¬ í•„ìš” ë¶„ì•¼ ({len(knowledge_gaps)}ê°œ):**")
        for i, gap in enumerate(knowledge_gaps, 1):
            st.markdown(f"{i}. {gap}")

    trends = landscape.get("methodological_trends", [])
    if trends:
        st.markdown(f"\n**ë°©ë²•ë¡ ì  ë™í–¥ ({len(trends)}ê°œ):**")
        for i, trend in enumerate(trends, 1):
            st.markdown(f"{i}. {trend}")

    controversies = landscape.get("controversies_or_debates", [])
    if controversies:
        st.markdown(f"\n**ë…¼ë€/ë¯¸í•´ê²° ìŸì  ({len(controversies)}ê°œ):**")
        for i, c in enumerate(controversies, 1):
            st.markdown(f"{i}. {c}")

    underexplored = landscape.get("underexplored_areas", [])
    if underexplored:
        st.markdown(f"\n**ë¯¸íƒêµ¬ ì˜ì—­ ({len(underexplored)}ê°œ):**")
        for i, area in enumerate(underexplored, 1):
            st.markdown(f"{i}. {area}")


def display_self_evaluation_results(evaluation: dict):
    """Display self-evaluation results"""
    st.markdown("---")
    st.markdown("## ğŸ¯ ìë™ í’ˆì§ˆ í‰ê°€")

    overall_score = evaluation.get("overall_score", 0)
    passed = evaluation.get("passed", False)

    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ì¢…í•© ì ìˆ˜", f"{overall_score}/10")
    with col2:
        status = "í•©ê²©" if passed else "ê²€í†  í•„ìš”"
        st.markdown(f"**ìƒíƒœ:** {status}")
    with col3:
        improvement_count = len(evaluation.get("improvements", []))
        st.metric("ê°œì„  í•­ëª©", improvement_count)

    # Detailed scores
    st.markdown("### ì„¸ë¶€ ì ìˆ˜")
    scores = evaluation.get("scores", {})
    cols = st.columns(4)
    criteria = list(scores.items())
    for i, (criterion, score) in enumerate(criteria):
        col_idx = i % 4
        with cols[col_idx]:
            if score >= 8:
                emoji = "âœ…"
            elif score >= 7:
                emoji = "O"
            elif score >= 5:
                emoji = "â–³"
            else:
                emoji = "X"
            st.write(f"{emoji} **{criterion.replace('_', ' ').title()}**")
            st.write(f"ì ìˆ˜: {score}/10")

    # Feedback
    feedback = evaluation.get("feedback", {})
    improvements = evaluation.get("improvements", [])

    st.markdown("### í‰ê°€ í”¼ë“œë°±")
    for criterion_key, fb_text in feedback.items():
        criterion_label = criterion_key.replace("_", " ").title()
        criterion_score = scores.get(criterion_key, "?")
        with st.expander(f"{criterion_label} (ì ìˆ˜: {criterion_score}/10)", expanded=False):
            st.markdown(f"**í”¼ë“œë°±:** {fb_text}")
            for imp in improvements:
                if imp["criterion"] == criterion_key:
                    st.markdown(f"\n**ê°œì„  ì œì•ˆ:** {imp.get('improvement', '')}")
                    break

    if not improvements:
        st.success("âœ… ëª¨ë“  ê¸°ì¤€ì—ì„œ 7ì  ì´ìƒì„ íšë“í–ˆìŠµë‹ˆë‹¤!")


def run_fact_check(generation_result: dict):
    """Run fact-checking on generated introduction"""
    st.markdown("### ğŸ” íŒ©íŠ¸ì²´í¬")

    with st.spinner("íŒ©íŠ¸ì²´í¬ ì§„í–‰ ì¤‘..."):
        try:
            fact_checker = FactChecker()
            check_result = fact_checker.verify_introduction(
                generation_result.get("introduction", ""),
                generation_result.get("articles_used", [])
            )

            st.session_state.fact_check_result = check_result

            accuracy = check_result.get("overall_accuracy", "UNKNOWN")
            st.metric("ì „ì²´ ì •í™•ë„", accuracy, delta="Verified")

            issues = check_result.get("issues", [])
            if issues:
                st.warning(f"âš ï¸ {len(issues)}ê°œì˜ ì ì¬ì  ë¬¸ì œ ë°œê²¬")
                for issue in issues:
                    st.write(f"- **{issue.get('type')}**: {issue.get('description', '')}")
            else:
                st.success("âœ… ëª¨ë“  ì¸ìš©ì´ ê²€ì¦ë˜ì—ˆìŠµë‹ˆë‹¤")

            st.info(check_result.get("summary", ""))

        except Exception as e:
            st.error(f"íŒ©íŠ¸ì²´í¬ ì‹¤íŒ¨: {str(e)}")
            logger.error(f"Fact check error: {e}", exc_info=True)


def run_revision(
    current_intro: str,
    revision_request: str,
    api_key: str,
    model: str,
    articles_used: list
):
    """Run revision on introduction"""
    if not revision_request.strip():
        st.warning("ìˆ˜ì • ìš”ì²­ì„ ì…ë ¥í•˜ì„¸ìš”")
        return

    try:
        from prompts.revision import get_revision_prompt

        st.markdown("### ìˆ˜ì • ì§„í–‰ ì¤‘...")
        progress_bar = st.progress(0)
        status_text = st.empty()

        status_text.write("Revision í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘...")
        progress_bar.progress(0.3)

        llm_client = get_llm_client(api_key=api_key, model=model)
        system_prompt, user_prompt = get_revision_prompt(
            current_intro, revision_request, articles_used
        )

        status_text.write("LLMìœ¼ë¡œ ìˆ˜ì • ìƒì„± ì¤‘...")
        progress_bar.progress(0.7)

        revised_intro = llm_client.generate(
            prompt=user_prompt,
            system_prompt=system_prompt,
            temperature=0.7,
            max_tokens=2000
        )

        progress_bar.progress(1.0)

        st.session_state.introduction_text = revised_intro
        st.session_state.current_intro = revised_intro
        st.success("âœ… ìˆ˜ì • ì™„ë£Œ!")

        st.markdown("### ìˆ˜ì •ëœ Introduction")
        st.markdown(revised_intro)

        if st.button("ìˆ˜ì • ë²„ì „ íŒ©íŠ¸ì²´í¬", key="revised_factcheck"):
            fact_checker = FactChecker()
            check_result = fact_checker.verify_introduction(revised_intro, articles_used)
            accuracy = check_result.get("overall_accuracy", "UNKNOWN")
            st.metric("ì •í™•ë„", accuracy)
            issues = check_result.get("issues", [])
            if issues:
                st.warning(f"âš ï¸ {len(issues)}ê°œ í•­ëª© í™•ì¸ í•„ìš”")
            else:
                st.success("âœ… íŒ©íŠ¸ì²´í¬ ì™„ë£Œ")

    except Exception as e:
        st.error(f"ìˆ˜ì • ì‹¤íŒ¨: {str(e)}")
        logger.error(f"Revision error: {e}", exc_info=True)


def _format_references_by_style(articles: list, style: str = "APA") -> list:
    """Format article list into citation strings"""
    refs = []
    for i, article in enumerate(articles, 1):
        authors = article.get("authors", [])
        title = article.get("title", "Untitled")
        journal = article.get("journal", "")
        journal_iso = article.get("journal_iso", journal)
        year = article.get("pub_year", "n.d.")
        pmid = article.get("pmid", "")
        doi = article.get("doi", "")

        if style == "APA":
            apa_authors = []
            for a in authors[:6]:
                parts = a.split()
                if len(parts) >= 2:
                    last = parts[0]
                    initials = ". ".join(p[0] + "." for p in parts[1:] if p)
                    apa_authors.append(f"{last}, {initials}")
                else:
                    apa_authors.append(a)
            if len(authors) > 6:
                author_str = ", ".join(apa_authors) + ", ... et al."
            elif len(apa_authors) > 1:
                author_str = ", ".join(apa_authors[:-1]) + ", & " + apa_authors[-1]
            elif apa_authors:
                author_str = apa_authors[0]
            else:
                author_str = "Unknown"
            doi_part = f" https://doi.org/{doi}" if doi else ""
            ref = f"{i}. {author_str} ({year}). {title}. *{journal_iso}*.{doi_part} PMID: {pmid}"

        elif style == "Vancouver":
            van_authors = []
            for a in authors[:3]:
                van_authors.append(a)
            if len(authors) > 3:
                author_str = ", ".join(van_authors) + " et al."
            else:
                author_str = ", ".join(van_authors)
            ref = f"{i}. {author_str}. {title}. {journal_iso}. {year}. PMID: {pmid}."

        else:  # AMA
            ama_authors = []
            for a in authors[:3]:
                ama_authors.append(a)
            if len(authors) > 3:
                author_str = ", ".join(ama_authors) + ", et al."
            else:
                author_str = ", ".join(ama_authors)
            ref = f"{i}. {author_str}. {title}. *{journal_iso}*. {year}. PMID: {pmid}."

        refs.append(ref)
    return refs


# ------------------------------------------------------------------
# Main
# ------------------------------------------------------------------

def main():
    """Main application flow â€” state machine dispatcher"""
    initialize_session()

    api_key, model, reference_style = setup_sidebar()

    display_header()
    st.markdown("---")

    state = st.session_state.pipeline_state

    if state == "IDLE":
        render_idle_state()
    elif state == "PARSING":
        render_parsing_state()
    elif state == "CONFIRM_QUERIES":
        render_confirm_queries_state()
    elif state == "RESEARCHING":
        render_researching_state()
    elif state == "CONFIRM_STRATEGY":
        render_confirm_strategy_state()
    elif state == "GENERATING":
        render_generating_state()
    elif state == "EVALUATING":
        render_evaluating_state()
    elif state == "SELF_EVOLVING":
        render_self_evolving_state()
    elif state == "COMPLETE":
        render_complete_state(reference_style=reference_style)
    else:
        st.error(f"Unknown pipeline state: {state}")
        reset_pipeline()
        st.rerun()


if __name__ == "__main__":
    main()
